{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Function Space Linearization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/neural-tangents/blob/notebook/Function_Space_Linearization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9uPYkWOcghJm",
        "pycharm": {}
      },
      "source": [
        "##### Copyright 2019 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YDnknGorgv2O",
        "pycharm": {}
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8KPv0bOW6UCi",
        "pycharm": {}
      },
      "source": [
        "#### Import & Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cxFbqXZKhGW0",
        "pycharm": {}
      },
      "source": [
        "Install JAX, Tensorflow Datasets, and Neural Tangents. \n",
        "\n",
        "The first line specifies the version of jaxlib that we would like to import. Note, that \"cp36\" species the version of python (version 3.6) used by JAX. Make sure your colab kernel matches this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g_gSbMyUhF92",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "!pip install --upgrade -q https://storage.googleapis.com/jax-releases/cuda$(echo $CUDA_VERSION | sed -e 's/\\.//' -e 's/\\..*//')/jaxlib-$(pip search jaxlib | grep -oP '[0-9\\.]+' | head -n 1)-cp36-none-linux_x86_64.whl\n",
        "!pip install --upgrade -q jax\n",
        "!pip install -q tensorflow-datasets\n",
        "!pip install -q git+https://www.github.com/google/neural-tangents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "knIftr57X055",
        "pycharm": {}
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8D0i89hRmNoC",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from jax.api import jit\n",
        "from jax.api import grad\n",
        "from jax import random\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax.experimental import stax\n",
        "from jax.experimental import optimizers\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "\n",
        "from neural_tangents import tangents\n",
        "from neural_tangents import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_bbZz-nWX4Hj",
        "pycharm": {}
      },
      "source": [
        "Define helper functions for processing data and defining a vanilla momentum optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W1ws1B-6_vq",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "def process_data(data_chunk):\n",
        "  \"\"\"Flatten the images and one-hot encode the labels.\"\"\"\n",
        "  image, label = data_chunk['image'], data_chunk['label']\n",
        "  \n",
        "  samples = image.shape[0]\n",
        "  image = np.array(np.reshape(image, (samples, -1)), dtype=np.float32)\n",
        "  image = (image - np.mean(image)) / np.std(image)\n",
        "  label = np.eye(10)[label]\n",
        "  \n",
        "  return {'image': image, 'label': label}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ik27L4izDK9s",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "@optimizers.optimizer\n",
        "def momentum(learning_rate, momentum=0.9):\n",
        "  \"\"\"A standard momentum optimizer for testing.\n",
        "\n",
        "  Different from `jax.experimental.optimizers.momentum` (Nesterov).\n",
        "  \"\"\"\n",
        "  learning_rate = optimizers.make_schedule(learning_rate)\n",
        "  def init_fun(x0):\n",
        "    v0 = np.zeros_like(x0)\n",
        "    return x0, v0\n",
        "  def update_fun(i, g, state):\n",
        "    x, velocity = state\n",
        "    velocity = momentum * velocity + g\n",
        "    x = x - learning_rate(i) * velocity\n",
        "    return x, velocity\n",
        "  def get_params(state):\n",
        "    x, _ = state\n",
        "    return x\n",
        "  return init_fun, update_fun, get_params\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "32Wvhil9X8IK",
        "pycharm": {}
      },
      "source": [
        "# Function Space Linearization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JJ_zDKsKcDB-",
        "pycharm": {}
      },
      "source": [
        "Create MNIST data pipeline using TensorFlow Datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5llaSqZW4Et3",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "dataset_size = 64\n",
        "\n",
        "train = tfds.load('mnist', split=tfds.Split.TRAIN, batch_size=dataset_size)\n",
        "train = process_data(next(tfds.as_numpy(train)))\n",
        "\n",
        "test = tfds.load('mnist', split=tfds.Split.TEST, batch_size=dataset_size)\n",
        "test = process_data(next(tfds.as_numpy(test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ajz_oTOw72v8",
        "pycharm": {}
      },
      "source": [
        "Setup some experiment parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UtjfeaYC72Gs",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "learning_rate = 1e0\n",
        "training_time = 1000.0\n",
        "print_every = 100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1-nKR--j5p2C",
        "pycharm": {}
      },
      "source": [
        "Create a Fully-Connected Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wIbfrdzq5pLZ",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "init_fn, f = stax.serial(\n",
        "    layers.Dense(4096), \n",
        "    stax.Tanh,\n",
        "    layers.Dense(10))\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "_, params = init_fn(key, (-1, 784))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c9zgKt9B8NBt",
        "pycharm": {}
      },
      "source": [
        "Construct the NTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bU6ccJM_8LWt",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "theta = tangents.ntk(f, batch_size=16)\n",
        "\n",
        "g_dd = theta(params, train['image'])\n",
        "g_td = theta(params, test['image'], train['image'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jdR-lIW11Vbj",
        "pycharm": {}
      },
      "source": [
        "Now that we have the NTK and a network we can compare against a number of different dynamics. Remember to reinitialize the network and NTK if you want to try a different dynamics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hVesciX61bGb",
        "pycharm": {}
      },
      "source": [
        "## Gradient Descent, MSE Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lrp9YNCt7nCj",
        "pycharm": {}
      },
      "source": [
        "Create a optimizer and initialize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-8i_4KD7o5s",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "opt_init, opt_apply, get_params = optimizers.sgd(learning_rate)\n",
        "state = opt_init(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NspVdDOU8mhk",
        "pycharm": {}
      },
      "source": [
        "Create an MSE loss and a gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z6L-LzyF8qLW",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "loss = lambda fx, y_hat: 0.5 * np.mean((fx - y_hat) ** 2)\n",
        "grad_loss = jit(grad(lambda params, x, y: loss(f(params, x), y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f57Teh1317hn",
        "pycharm": {}
      },
      "source": [
        "Create an MSE predictor and compute the function space values of the network at initialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7UH_uOxz16w2",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "predictor = tangents.analytic_mse_predictor(g_dd, train['label'])\n",
        "fx_train = f(params, train['image'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rWROOyCZ9u6N",
        "pycharm": {}
      },
      "source": [
        "Train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXeof-AB8BiV",
        "outputId": "13d984b3-5667-4f9c-8c87-141aac9566b1",
        "pycharm": {},
        "colab": {
          "height": 215
        }
      },
      "source": [
        "print ('Time\\tLoss\\tLinear Loss')\n",
        "print_every_step = int(print_every // learning_rate)\n",
        "\n",
        "X, Y = train['image'], train['label']\n",
        "\n",
        "for i in range(int(training_time // learning_rate)):\n",
        "  params = get_params(state)\n",
        "  state = opt_apply(i, grad_loss(params, X, Y), state)\n",
        "  \n",
        "  if i % print_every_step == 0:\n",
        "    t = i * learning_rate\n",
        "    exact_loss = loss(f(params, X), Y)\n",
        "    linear_loss = loss(predictor(fx_train, t), Y)\n",
        "    print('{}\\t{:.4f}\\t{:.4f}'.format(t, exact_loss, linear_loss))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time\tLoss\tLinear Loss\n",
            "0.0\t0.2234\t0.2234\n",
            "100.0\t0.0997\t0.0998\n",
            "200.0\t0.0756\t0.0756\n",
            "300.0\t0.0600\t0.0601\n",
            "400.0\t0.0492\t0.0492\n",
            "500.0\t0.0413\t0.0413\n",
            "600.0\t0.0354\t0.0353\n",
            "700.0\t0.0307\t0.0307\n",
            "800.0\t0.0269\t0.0269\n",
            "900.0\t0.0239\t0.0238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gx65YR3A8_yd",
        "pycharm": {}
      },
      "source": [
        "## Gradient Descent, Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8jEb5V9C8_yd",
        "pycharm": {}
      },
      "source": [
        "Create a optimizer and initialize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKfuj6O88_ye",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "opt_init, opt_apply, get_params = optimizers.sgd(learning_rate)\n",
        "state = opt_init(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hpWaHdvH8_yg",
        "pycharm": {}
      },
      "source": [
        "Create an Cross Entropy loss and a gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQ03wQ7O8_yh",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "loss = lambda fx, y_hat: -np.mean(stax.logsoftmax(fx) * y_hat)\n",
        "grad_loss = jit(grad(lambda params, x, y: loss(f(params, x), y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WgS4k3878_yi",
        "pycharm": {}
      },
      "source": [
        "Create a Gradient Descent predictor and compute the function space values of the network at initialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h2uIi4mQ8_yi",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "predictor = tangents.gradient_descent_predictor(g_dd, train['label'], loss)\n",
        "fx_train = f(params, train['image'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tRh7Ur9Y8_yj",
        "pycharm": {}
      },
      "source": [
        "Train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FnW6DNWf8_yj",
        "outputId": "fb354207-74b5-4516-af6c-de72b6a0671c",
        "pycharm": {},
        "colab": {
          "height": 253
        }
      },
      "source": [
        "print ('Time\\tLoss\\tLinear Loss')\n",
        "print_every_step = int(print_every // learning_rate)\n",
        "\n",
        "X, Y = train['image'], train['label']\n",
        "\n",
        "for i in range(int(training_time // learning_rate)):\n",
        "  params = get_params(state)\n",
        "  state = opt_apply(i, grad_loss(params, X, Y), state)\n",
        "  \n",
        "  if i % print_every_step == 0:\n",
        "    t = i * learning_rate\n",
        "    exact_loss = loss(f(params, X), Y)\n",
        "    linear_loss = loss(predictor(fx_train, t), Y)\n",
        "    print('{:.0f}\\t{:.4f}\\t{:.4f}'.format(t, exact_loss, linear_loss))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time\tLoss\tLinear Loss\n",
            "0\t0.1701\t0.1701\n",
            "100\t0.1506\t0.1507\n",
            "200\t0.1354\t0.1357\n",
            "300\t0.1232\t0.1238\n",
            "400\t0.1132\t0.1141\n",
            "500\t0.1047\t0.1059\n",
            "600\t0.0973\t0.0987\n",
            "700\t0.0908\t0.0925\n",
            "800\t0.0851\t0.0868\n",
            "900\t0.0799\t0.0818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vc2FaYtEDBJ_",
        "pycharm": {}
      },
      "source": [
        "## Momentum, Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L4onegU1DBKA",
        "pycharm": {}
      },
      "source": [
        "Create a optimizer and initialize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cxoiw-DADBKB",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "opt_init, opt_apply, get_params = momentum(learning_rate, 0.9)\n",
        "state = opt_init(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "63VJ8y9FDBKE",
        "pycharm": {}
      },
      "source": [
        "Create a Cross Entropy loss and a gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e8SxBiZXDBKE",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "loss = lambda fx, y_hat: -np.mean(stax.logsoftmax(fx) * y_hat)\n",
        "grad_loss = jit(grad(lambda params, x, y: loss(f(params, x), y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t7GiiW-LDBKI",
        "pycharm": {}
      },
      "source": [
        "Create a momentum predictor and initialize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8fpKKqPaDBKJ",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "pred_init, predictor, get = tangents.momentum_predictor(\n",
        "    g_dd, train['label'], loss, learning_rate)\n",
        "fx_train = f(params, train['image'])\n",
        "pred_state = pred_init(fx_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jW9ws4fMDBKL",
        "pycharm": {}
      },
      "source": [
        "Train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_pfseUitDBKM",
        "outputId": "8ae4d8c1-c9bc-4774-dafd-86a50e355286",
        "pycharm": {},
        "colab": {
          "height": 127
        }
      },
      "source": [
        "print ('Time\\tLoss\\tLinear Loss')\n",
        "print_every_step = int(print_every // np.sqrt(learning_rate))\n",
        "\n",
        "X, Y = train['image'], train['label']\n",
        "\n",
        "for i in range(int(300.0 // np.sqrt(learning_rate))):\n",
        "  params = get_params(state)\n",
        "  state = opt_apply(i, grad_loss(params, X, Y), state)\n",
        "  \n",
        "  if i % print_every_step == 0:\n",
        "    t = i * np.sqrt(learning_rate)\n",
        "    exact_loss = loss(f(params, X), Y)\n",
        "    linear_loss = loss(get(predictor(pred_state, t)), Y)\n",
        "    print('{:.0f}\\t{:.4f}\\t{:.4f}'.format(t, exact_loss, linear_loss))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time\tLoss\tLinear Loss\n",
            "0\t0.0753\t0.0753\n",
            "100\t0.0471\t0.0496\n",
            "200\t0.0321\t0.0343\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}